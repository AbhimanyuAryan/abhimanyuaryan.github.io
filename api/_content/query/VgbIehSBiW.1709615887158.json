{"_path":"/deep-learning/6-introduction-to-nlp","_dir":"deep-learning","_draft":false,"_partial":false,"_locale":"","title":"Introduction to NLP","description":"We see texts as a sequence of words, but computers see them as a sequence of numbers. This is the first step in understanding how NLP works. In this article, we will learn about the basics of NLP and how it works.","date":"2024-03-3","author":"Aryan","body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We see texts as a sequence of words, but computers see them as a sequence of numbers. This is the first step in understanding how NLP works. In this article, we will learn about the basics of NLP and how it works."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Texts are converted into numeric vectors, where words (or other types of tokens) are encoded as numbers. This is done using a technique called tokenization. Once the text is tokenized, it can be used as input to machine learning models."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Most commonly used representation for words: One-hot encoding and Word embeddings."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Vocabulary: The set of unique words in a text."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"One-hot encoding: Each word is represented as a vector of 0s and 1s. The length of the vector is equal to the size of the vocabulary. The vector has 1 at the index of the word in the vocabulary and 0s elsewhere."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Lets say if the vocabulary is "},{"type":"element","tag":"span","props":{},"children":[{"type":"text","value":"\"I\", \"am\", \"happy\""}]},{"type":"text","value":", then the word \"I\" will be represented as "},{"type":"element","tag":"span","props":{},"children":[{"type":"text","value":"1, 0, 0"}]},{"type":"text","value":", \"am\" as "},{"type":"element","tag":"span","props":{},"children":[{"type":"text","value":"0, 1, 0"}]},{"type":"text","value":" and \"happy\" as "},{"type":"element","tag":"span","props":{},"children":[{"type":"text","value":"0, 0, 1"}]},{"type":"text","value":"."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"\"I\" is represented as one-hot encoding because it is the first word in the vocabulary, \"am\" is the second word and \"happy\" is the third word."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"rnns","src":"/deep-learning/introduction-to-nlp/NLP.png"},"children":[]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:deep-learning:6-introduction-to-nlp.md","_source":"content","_file":"deep-learning/6-introduction-to-nlp.md","_extension":"md"}
[{"data":1,"prerenderedAt":98},["Reactive",2],{"content-query-EZwi1R3ovR":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":7,"title":8,"description":9,"date":10,"author":11,"body":12,"_type":93,"_id":94,"_source":95,"_file":96,"_extension":97},"/deep-learning/6-introduction-to-nlp","deep-learning",false,"","Introduction to NLP","We see texts as a sequence of words, but computers see them as a sequence of numbers. This is the first step in understanding how NLP works. In this article, we will learn about the basics of NLP and how it works.","2024-03-3","Aryan",{"type":13,"children":14,"toc":90},"root",[15,22,27,32,37,42,76,81],{"type":16,"tag":17,"props":18,"children":19},"element","p",{},[20],{"type":21,"value":9},"text",{"type":16,"tag":17,"props":23,"children":24},{},[25],{"type":21,"value":26},"Texts are converted into numeric vectors, where words (or other types of tokens) are encoded as numbers. This is done using a technique called tokenization. Once the text is tokenized, it can be used as input to machine learning models.",{"type":16,"tag":17,"props":28,"children":29},{},[30],{"type":21,"value":31},"Most commonly used representation for words: One-hot encoding and Word embeddings.",{"type":16,"tag":17,"props":33,"children":34},{},[35],{"type":21,"value":36},"Vocabulary: The set of unique words in a text.",{"type":16,"tag":17,"props":38,"children":39},{},[40],{"type":21,"value":41},"One-hot encoding: Each word is represented as a vector of 0s and 1s. The length of the vector is equal to the size of the vocabulary. The vector has 1 at the index of the word in the vocabulary and 0s elsewhere.",{"type":16,"tag":17,"props":43,"children":44},{},[45,47,53,55,60,62,67,69,74],{"type":21,"value":46},"Lets say if the vocabulary is ",{"type":16,"tag":48,"props":49,"children":50},"span",{},[51],{"type":21,"value":52},"\"I\", \"am\", \"happy\"",{"type":21,"value":54},", then the word \"I\" will be represented as ",{"type":16,"tag":48,"props":56,"children":57},{},[58],{"type":21,"value":59},"1, 0, 0",{"type":21,"value":61},", \"am\" as ",{"type":16,"tag":48,"props":63,"children":64},{},[65],{"type":21,"value":66},"0, 1, 0",{"type":21,"value":68}," and \"happy\" as ",{"type":16,"tag":48,"props":70,"children":71},{},[72],{"type":21,"value":73},"0, 0, 1",{"type":21,"value":75},".",{"type":16,"tag":17,"props":77,"children":78},{},[79],{"type":21,"value":80},"\"I\" is represented as one-hot encoding because it is the first word in the vocabulary, \"am\" is the second word and \"happy\" is the third word.",{"type":16,"tag":17,"props":82,"children":83},{},[84],{"type":16,"tag":85,"props":86,"children":89},"img",{"alt":87,"src":88},"rnns","/deep-learning/introduction-to-nlp/NLP.png",[],{"title":7,"searchDepth":91,"depth":91,"links":92},2,[],"markdown","content:deep-learning:6-introduction-to-nlp.md","content","deep-learning/6-introduction-to-nlp.md","md",1709615896127]
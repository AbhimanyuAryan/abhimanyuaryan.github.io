<!DOCTYPE html><html><head><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Non-stop train to LLM</title>
<meta property="og:title" content="Non-stop train to LLM">
<link rel="preload" as="fetch" crossorigin="anonymous" href="/deep-learning/5-train-to-llm/_payload.json">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/entry.CqSTrnYL.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/_slug_.Ca0F_hXe.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRenderer.Bw8gG7Ya.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.vue.3vrM733r.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/index.BsYmvPZw.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/preview.BPmUqimh.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentDoc.DaxL4aO3.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/vue.f36acd1f.D86RikEK.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentQuery.BcEffIQN.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/query.B5ADSXdC.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.CgLN8wV9.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH1.DcJBUaT8.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH2.B6BLI2_A.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH3.CKvdYNDt.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseUl.BwsPW5YL.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseLi.ZKYs8-W1.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseStrong.CG27rcsW.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseP.C14wsJGp.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/error-404.hTBb1uJa.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/nuxt-link.CpgBD75x.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/error-500.Dq35phKF.js">
<script type="module" src="/_nuxt/entry.CqSTrnYL.js" crossorigin></script></head><body><div id="__nuxt"><!--[--><main><!--[--><article><h1>Non-stop train to LLM</h1><div><h1 id="how-to-train-your-chatgpt"><!--[-->How to Train Your ChatGPT<!--]--></h1><h2 id="stage-1-pretraining"><a href="#stage-1-pretraining"><!--[-->Stage 1: Pretraining<!--]--></a></h2><h3 id="_1-data-collection"><a href="#_1-data-collection"><!--[-->1. Data Collection:<!--]--></a></h3><ul><!--[--><li><!--[--><strong><!--[-->Scope and Diversity:<!--]--></strong> Aim for a dataset that&#39;s broad and diverse, covering a wide range of topics, languages, and formats.<!--]--></li><li><!--[--><strong><!--[-->Cleaning and Preprocessing:<!--]--></strong> Remove duplicates, low-quality content, and non-text elements. Normalize text for consistency.<!--]--></li><li><!--[--><strong><!--[-->Ethical and Legal Considerations:<!--]--></strong> Ensure compliance with privacy laws and copyright guidelines.<!--]--></li><!--]--></ul><h3 id="_2-infrastructure-setup"><a href="#_2-infrastructure-setup"><!--[-->2. Infrastructure Setup:<!--]--></a></h3><ul><!--[--><li><!--[--><strong><!--[-->Choosing Hardware:<!--]--></strong> Select high-performance GPUs with significant VRAM. NVIDIA&#39;s offerings or cloud-based solutions are recommended.<!--]--></li><li><!--[--><strong><!--[-->Distributed Training:<!--]--></strong> Use TensorFlow, PyTorch with Horovod, or NVIDIA&#39;s NCCL for efficient workload management across GPUs.<!--]--></li><li><!--[--><strong><!--[-->Approximate Cost and Time:<!--]--></strong> Expect to use around 6,000 GPUs, costing nearly $2 million, and wait approximately 12 days for the model to train.<!--]--></li><!--]--></ul><h3 id="_3-training-process"><a href="#_3-training-process"><!--[-->3. Training Process:<!--]--></a></h3><ul><!--[--><li><!--[--><strong><!--[-->Model Architecture and Hyperparameter Tuning:<!--]--></strong> Choose the model&#39;s architecture and experiment with hyperparameters.<!--]--></li><li><!--[--><strong><!--[-->Monitoring and Optimization:<!--]--></strong> Implement techniques like mixed-precision training to optimize training time and resource use.<!--]--></li><!--]--></ul><h3 id="_4-model-evaluation-and-iteration"><a href="#_4-model-evaluation-and-iteration"><!--[-->4. Model Evaluation and Iteration:<!--]--></a></h3><ul><!--[--><li><!--[--><strong><!--[-->Baseline Testing and Iterative Refinement:<!--]--></strong> Conduct tests to ensure learning efficacy and refine based on initial outcomes.<!--]--></li><!--]--></ul><h2 id="stage-2-finetuning"><a href="#stage-2-finetuning"><!--[-->Stage 2: Finetuning<!--]--></a></h2><h3 id="_1-instruction-design"><a href="#_1-instruction-design"><!--[-->1. Instruction Design:<!--]--></a></h3><ul><!--[--><li><!--[--><strong><!--[-->Clear Objectives and Iterative Improvement:<!--]--></strong> Develop precise labeling instructions, refining them based on initial labeling outcomes.<!--]--></li><!--]--></ul><h3 id="_2-data-annotation"><a href="#_2-data-annotation"><!--[-->2. Data Annotation:<!--]--></a></h3><ul><!--[--><li><!--[--><strong><!--[-->Quality Control and Diversity in Responses:<!--]--></strong> Ensure high-quality labeling and collect data with various tones and perspectives.<!--]--></li><li><!--[--><strong><!--[-->Approximate Cost and Time:<!--]--></strong> Hiring people or using services like scale.ai to collect 100k high-quality Q&amp;A responses and/or comparisons can vary in cost but is generally less expensive than the initial pretraining phase. Expect the finetuning process to take around 1 day.<!--]--></li><!--]--></ul><h3 id="_3-finetuning-process"><a href="#_3-finetuning-process"><!--[-->3. Finetuning Process:<!--]--></a></h3><ul><!--[--><li><!--[--><strong><!--[-->Selecting a Subset and Adapting the Model:<!--]--></strong> Choose a relevant subset for finetuning and adjust hyperparameters to prevent overfitting.<!--]--></li><!--]--></ul><h3 id="_4-evaluation-and-deployment"><a href="#_4-evaluation-and-deployment"><!--[-->4. Evaluation and Deployment:<!--]--></a></h3><ul><!--[--><li><!--[--><strong><!--[-->Performance Metrics and Real-World Testing:<!--]--></strong> Establish success metrics and test the model in controlled environments or with beta users.<!--]--></li><!--]--></ul><h2 id="approximate-timings-and-costs-summary"><a href="#approximate-timings-and-costs-summary"><!--[-->Approximate Timings and Costs Summary:<!--]--></a></h2><ul><!--[--><li><!--[--><strong><!--[-->Pretraining Phase:<!--]--></strong> ~12 days of training on a cluster of ~6,000 GPUs, costing around $2 million.<!--]--></li><li><!--[--><strong><!--[-->Finetuning Phase:<!--]--></strong> ~1 day of finetuning, with costs depending on the scale of data annotation but generally less than the pretraining phase.<!--]--></li><!--]--></ul><p><!--[-->wip ðŸš§<!--]--></p></div></article><!--]--></main><!--]--></div><script type="application/json" id="__NUXT_DATA__" data-ssr="true" data-src="/deep-learning/5-train-to-llm/_payload.json">[{"state":1,"once":3,"_errors":5,"serverRendered":8,"path":9,"prerenderedAt":10},["Reactive",2],{},["Reactive",4],["Set"],["Reactive",6],{"content-query-vUyMCR5aG4":7},null,true,"/deep-learning/5-train-to-llm",1708883461710]</script>
<script>window.__NUXT__={};window.__NUXT__.config={public:{mdc:{components:{prose:true,map:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"ProseCodeInline",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"}},headings:{anchorLinks:{h1:false,h2:true,h3:true,h4:true,h5:false,h6:false}}},content:{locales:[],defaultLocale:"",integrity:1708883453161,experimental:{stripQueryParameters:false,advanceQuery:false,clientDB:false},respectPathCase:false,api:{baseURL:"/api/_content"},navigation:{fields:[]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"ProseCodeInline",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:false,wsUrl:"",documentDriven:false,host:"",trailingSlash:false,search:"",contentHead:true,anchorLinks:{depth:4,exclude:[1]}}},app:{baseURL:"/",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script></body></html>